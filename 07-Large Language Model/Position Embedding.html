<!DOCTYPE HTML>
<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="Atom feed">
    <title>Position Embedding - zwt的个人wiki</title>
    <meta name="keywords" content="Memory."/>
    <meta name="description" content="Wiki."/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  </head>

  <body>
  <div id="container" style = "width: 65em">
      
<div id="header">
  <div class="post-nav"><a href="/wiki/">Home</a>&nbsp;&#187;&nbsp;<a href="/wiki/#07-Large Language Model">07-Large Language Model</a>&nbsp;&#187;&nbsp;Position Embedding
    <span class="updated">Page Updated&nbsp;
      2024-01-14
    </span></div>
</div>
<div class="clearfix"></div>

<div class="page_title">Position Embedding</div>

  <h2 id="_1">主要内容</h2>
<ul>
<li>
<p>sinusoidal，三角函数位置编码</p>
<ul>
<li>每个位置编码是独特的</li>
<li>周期性确保了编码的连续和平滑</li>
<li>随着位置距离的增大，向量内积有趋近于0的趋势<br />
<div style="text-align: center"><img src="/wiki/attach/images/POS-01.png" style="max-width:600px"></div></li>
</ul>
</li>
<li>
<p>RoPE(Rotary Position Embedding)，旋转位置编码</p>
<ul>
<li>更直接地表示相对位置关系</li>
<li>在attention计算的内积操作中加入相对位置信息，即实现下列表达式<br />
<div style="text-align: center"><img src="/wiki/attach/images/POS-02.png" style="max-width:400px"></div></li>
<li>论文找到一个表达式满足上述关系<br />
<div style="text-align: center"><img src="/wiki/attach/images/POS-03.png" style="max-width:500px"></div></li>
<li>假设是2维的情况，f函数进行推导后可以得到<br />
<div style="text-align: center"><img src="/wiki/attach/images/POS-04.png" style="max-width:500px"></div></li>
<li>再进行推导就得到了如下表达式<br />
<div style="text-align: center"><img src="/wiki/attach/images/POS-05.png" style="max-width:600px"></div></li>
<li>扩展到多维的情况，表达式如下<br />
<div style="text-align: center"><img src="/wiki/attach/images/POS-06.png" style="max-width:400px"></div><br />
<div style="text-align: center"><img src="/wiki/attach/images/POS-07.png" style="max-width:600px"></div></li>
<li>因为矩阵很稀疏，所以可以简化为<br />
<div style="text-align: center"><img src="/wiki/attach/images/POS-08.png" style="max-width:600px"></div></li>
<li>逻辑简单可以如下理解<br />
<div style="text-align: center"><img src="/wiki/attach/images/POS-09.png" style="max-width:700px"></div></li>
<li>RoPE 形式上和Sinusoidal类似，Sinusoidal是加性的，RoPE是乘性的</li>
<li>RoPE沿用了Sinusoidal中theta的定义，即\theta_i = 10000^{-2i/d}，它可以带来一定的远程衰减性。</li>
</ul>
</li>
<li>
<p>ALiBi</p>
<ul>
<li>使用sinusoidal的transformer的外推能力较弱，虽然RoPE有所改进，但也没有达到预期。</li>
<li>为了有效地实现外推，ALiBi不向单词embedding中添加位置embedding，而是根据token之间的距离给attention score加上一个预设好的偏置矩阵<br />
<div style="text-align: center"><img src="/wiki/attach/images/POS-10.png" style="max-width:600px"></div></li>
<li>ALiBi不需要对原始网络进行改动，允许在较短的输入序列上训练模型，同时在推理时能够有效地外推到较长的序列，从而实现了更高的效率和性能。</li>
</ul>
</li>
</ul>
    </div>
    <div id="footer">
      <span>
        <p>Copyright © 2024 zwt.
        Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.</p>
        <p>Site Generated 2024-11-26 14:57:26</p>
      </span>
    </div>

    
    
  </body>
</html>