<!DOCTYPE HTML>
<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="Atom feed">
    <title>Pattern Recognition and Machine Learning - zwt的个人wiki</title>
    <meta name="keywords" content="Memory."/>
    <meta name="description" content="Wiki."/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  </head>

  <body>
  <div id="container" style = "width: 65em">
      
<div id="header">
  <div class="post-nav"><a href="/wiki/">Home</a>&nbsp;&#187;&nbsp;<a href="/wiki/#09-Book">09-Book</a>&nbsp;&#187;&nbsp;Pattern Recognition and Machine Learning
    <span class="updated">Page Updated&nbsp;
      2021-07-01
    </span></div>
</div>
<div class="clearfix"></div>

<div class="page_title">Pattern Recognition and Machine Learning</div>

  <h2 id="_1">主要内容</h2>
<ul>
<li>
<p>1 绪论</p>
<ul>
<li>频率学家观点——统计机器学习（优化问题，参数是定值）<ul>
<li>定义模型，构造损失函数，求解最优化问题</li>
</ul>
</li>
<li>贝叶斯观点——概率图模型（积分问题，参数是分布）<ul>
<li>推断后验概率，均值、方差，积分问题，数值计算方法MCMC</li>
<li>有向（贝叶斯网络），无向（马尔可夫网络）</li>
<li>时间相关，离散（HMM隐马尔可夫），线性（卡尔曼滤波），非线性（Particle滤波）</li>
</ul>
</li>
<li>概率论<ul>
<li>概率密度（概率密度转换公式）、期望、协方差、贝叶斯概率</li>
<li>先验概率、后验概率、条件概率、边缘概率</li>
</ul>
</li>
<li>决策论<ul>
<li>最小化错误分类概率、最小化期望损失、拒绝选项、推断和决策</li>
</ul>
</li>
<li>信息论<ul>
<li>信息熵、相对熵（KL散度）、互信息 </li>
</ul>
</li>
<li>概率生成/概率判别模型<ul>
<li>生成模型与判别模型是指不同的数据建模方式，区别是是对P（y|x）还是对P（x，y）建模</li>
<li>频率学派与贝叶斯学派是两种学派对于概率的看法不同而分的派系，参数是定值还是概率分布</li>
<li>两者之间没有必然联系</li>
</ul>
</li>
</ul>
</li>
<li>
<p>2 概率分布</p>
<ul>
<li>方差和贝塞尔修正（分母为N-1）</li>
<li>密度估计，在已知{xi}的情况下对p(x)建模</li>
<li>参数分布，少量可调节的参数决定了这个概率分布</li>
<li>贝叶斯角度，后验=先验*似然</li>
<li>共轭先验，使得后验概率分布和先验概率分布一致<ul>
<li>多项式分布 - 狄利克雷分布</li>
<li>高斯分布 - 高斯分布</li>
<li>二项分布 - Beta分布</li>
</ul>
</li>
<li>高斯分布的最大似然和贝叶斯推断</li>
<li>最大似然估计，均值无偏，方差有偏（偏小）</li>
<li>多元高斯分布的变体，相关系数矩阵分解，参数个数</li>
<li>指数族分布<ul>
<li>伯努利分布的指数形式，多项式分布的指数形式</li>
<li>最大似然与充分统计量</li>
<li>共轭先验还是指数族分布</li>
<li>无信息先验</li>
</ul>
</li>
</ul>
</li>
<li>
<p>3 线性回归</p>
<ul>
<li>线性基函数模型</li>
<li>最大似然与最小平方（奇异矩阵，参数很大，通过加正则项来解决）</li>
<li>偏置方差</li>
<li>贝叶斯线性回归（先验分布、似然分布、后验分布和预测分布）</li>
<li>最小二乘与几何意义<ul>
<li>最小二乘推导</li>
<li>两种几何解释<ul>
<li>最小化误差距离</li>
<li>在x构成的空间内找最接近y的函数（X和Y-aX垂直）</li>
</ul>
</li>
</ul>
</li>
<li>最大似然角度推导</li>
<li>正则化，频率/贝叶斯 两个角度的推导</li>
<li>LSE（最小二乘）== MLE（高斯噪声）</li>
<li>Regularized LES == MAP（贝叶斯回归，高斯先验，高斯噪声）</li>
</ul>
</li>
<li>
<p>4 线性分类</p>
<ul>
<li>频率派：统计机器学习，贝叶斯派：概率图模型</li>
<li>线性<ul>
<li>属性非线性-多项式回归</li>
<li>全局非线性-0/1分类</li>
<li>系数非线性-神经网络</li>
</ul>
</li>
<li>全局性<ul>
<li>决策树</li>
<li>线性样条回归</li>
</ul>
</li>
<li>数据加工<ul>
<li>PCA</li>
<li>流形</li>
</ul>
</li>
<li>线性分类<ul>
<li>硬分类，0或1<ul>
<li>svm</li>
<li>感知机</li>
<li>线性判别分析，fisher</li>
</ul>
</li>
</ul>
</li>
<li>软分类，0～1取值<ul>
<li>生成式，高斯判别分析（连续），朴素贝叶斯（离散）</li>
<li>判别式，lr</li>
</ul>
</li>
<li>二分类与多分类</li>
<li>分类中的最小平方</li>
<li>fisher线性判别函数（确定投影方向），与最小平方一致</li>
<li>感知器算法</li>
</ul>
</li>
<li>
<p>5 神经网络</p>
</li>
<li>
<p>6 核方法</p>
</li>
<li>
<p>降维</p>
<ul>
<li>直接降维（特征选择）</li>
<li>线性降维，PCA，MDS</li>
<li>非线性降维，流形（LLE局部线性嵌入，soimap）</li>
</ul>
</li>
<li>
<p>7 SVM</p>
<ul>
<li>二次凸优化问题</li>
<li>约束优化问题——对偶问题</li>
</ul>
</li>
<li>
<p>8 概率图模型</p>
<ul>
<li>概率图结构，tail-to-tail/tail-to-head/head-to-head<ul>
<li>tail-to-tail/tail-to-head，节点已知则路径两侧独立。</li>
<li>head-to-head，节点与子节点未知则路径两侧独立。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>9 EM</p>
</li>
<li>
<p>10 近似推断</p>
</li>
<li>
<p>11 采样方法</p>
<ul>
<li>精确推断不可行，故使用采样方法；虽然我们感兴趣的是⾮观测变量上的后验概率分布本⾝，但是在⼤部分情况下后验概率分布的主要⽤途是计算期望，例如做预测的场景。</li>
<li>概率密度转换公式，利用简单分布采样能力对复杂分布进行采样。</li>
<li>拒绝采样：已知概率密度相对值，但归一化系数难以计算的情况；为了降低拒绝概率，proposal分布应该尽可能的接近目标分布；proposal分布选择难度高，可以利用切线来构造；拒绝采样不适合高维空间。</li>
<li>重要性采样：通过一个相似的proposal简单分布采样来近似目标分布，其中对不同的采样值进行了重要性权重的修正。</li>
<li>蒙特卡罗EM算法：EM中E步骤无法解析计算的模型用采样方法来近似。</li>
<li>MCMC<ul>
<li>蒙特卡洛方法：通过采样样本来近似代表所有样本，当采样样本数量足够大时，采样样本就可以近似全部样本；蒙特卡洛方法求圆周率。</li>
<li>随机过程：随时间变化的一系列随机变量。</li>
<li>马尔可夫性质：t+1状态的取值只取决于t状态。</li>
<li>马尔可夫过程：具有马尔可夫性质的随机过程成为马尔可夫过程，也可定义为连续指数集的马尔可夫链。</li>
<li>平稳性分布性质：系统在随机时间所在状态的概率是确定的，即平稳分布，也成为静态分布。</li>
<li>马尔可夫链蒙特卡洛方法（MCMC）：是一类以期望分布为平稳分布的马尔可夫链为基础，对概率分布进行抽样的算法。</li>
<li>整体思路：为了对后验分布进行采样，构建一个马尔可夫链（利用似然比来作为接受率，然后用蒙特卡洛方法进行采样），其稳态的分布与后验分布一致。</li>
<li>吉布斯采样：用于在难以直接采样时从某一多变量概率分布中近似抽取样本序列。</li>
</ul>
</li>
</ul>
</li>
<li>
<p>12 连续潜在变量</p>
</li>
<li>
<p>13 顺序数据</p>
</li>
<li>
<p>14 组合模型</p>
</li>
</ul>
    </div>
    <div id="footer">
      <span>
        <p>Copyright © 2022 zwt.
        Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.</p>
        <p>Site Generated 2022-01-06 11:34:15</p>
      </span>
    </div>

    
    
  </body>
</html>