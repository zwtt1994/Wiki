---
title: "2015-Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
layout: page
date: 2020-11-15
---


## 总结

- 

## 主要内容

- 由于梯度消失/梯度爆炸的存在，神经网络越深会导致网络更难训练。同时在前向传播时底层的轻微扰动可能会使得深层的网络输出发生比较大的变化。

- 

