---
title: "2024-对比学习"
layout: page
date: 2024-02-29
---

## 基本概念

- 对比学习（Contrastive Learning）是一种自监督学习（Self-supervised Learning）方法，主要用于无监督或半监督的特征表示学习。
- 对比学习的核心思想是通过比较样本之间的相似性和差异性，使得相似样本的特征表示更接近，不相似样本的特征表示更远离。
- 对比学习的典型范式是"代理任务+目标函数"，代理任务和目标函数也是对比学习与有监督学习最大的区别，对比学习没有ground truth。
<div style="text-align: center"><img src="/wiki/attach/images/Contrastive-01.png" style="max-width:600px"></div>
    - 代理任务一般是数据增强、多视角、多模态或者某些业务逻辑。
    - 特征提取和MLP其实就是模型网络结构输出预估目标，例如表征向量。
    - 损失函数一般是infoNCE（noise contrastive estimation）
        - NCE是将问题转化为二分类，但二分类信息量太小了
<div style="text-align: center"><img src="/wiki/attach/images/Contrastive-02.png" style="max-width:600px"></div>
        - infoNCE进一步优化为负采样的多分类，其中温度系数很重要，温度系数越大相当于都是弱负样本，温度系数越小则都是强负样本。
<div style="text-align: center"><img src="/wiki/attach/images/Contrastive-03.png" style="max-width:400px"></div>


## 相关研究

- Representation Learning with Contrastive Predictive Coding(word2vec)
<div style="text-align: center"><img src="/wiki/attach/images/Contrastive-04.png" style="max-width:600px"></div>

- Momentum Contrast for Unsupervised Visual Representation Learning
    - 给予对比学习，将模型学到的特征用于分类。
<div style="text-align: center"><img src="/wiki/attach/images/Contrastive-05.png" style="max-width:600px"></div>


- A Simple Framework for Contrastive Learning of Visual Representations
    - 视觉表征对于同一目标不同视角的输入都应具有不变性
<div style="text-align: center"><img src="/wiki/attach/images/Contrastive-06.png" style="max-width:600px"></div>

- Supervised Contrastive Learning
    - 自监督只做自己的变换，可能会过拟合，因此提出有监督对比学习，Triplet Loss
    - 本质上还是InfoNCE Loss
<div style="text-align: center"><img src="/wiki/attach/images/Contrastive-07.png" style="max-width:400px"></div>
