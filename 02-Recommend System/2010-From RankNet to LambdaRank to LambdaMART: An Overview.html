<!DOCTYPE HTML>
<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="Atom feed">
    <title>2010-From RankNet to LambdaRank to LambdaMART: An Overview - zwt的个人wiki</title>
    <meta name="keywords" content="Memory."/>
    <meta name="description" content="Wiki."/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  </head>

  <body>
  <div id="container" style = "width: 65em">
      
<div id="header">
  <div class="post-nav"><a href="/wiki/">Home</a>&nbsp;&#187;&nbsp;<a href="/wiki/#02-Recommend System">02-Recommend System</a>&nbsp;&#187;&nbsp;2010-From RankNet to LambdaRank to LambdaMART: An Overview
    <span class="updated">Page Updated&nbsp;
      2021-02-11
    </span></div>
</div>
<div class="clearfix"></div>

<div class="page_title">2010-From RankNet to LambdaRank to LambdaMART: An Overview</div>

  <h2 id="_1">总结</h2>
<ul>
<li>RankNet引入了pair-wise的排序思想，LambdaRank定义了pair-wise的梯度，LambdaMART利用GBDT来进行学习。</li>
</ul>
<h2 id="_2">主要内容</h2>
<ul>
<li>
<p>RankNet：pair-wise的基础思想</p>
<ul>
<li>在两个item通过排序模型计算出得分之后，通过sigmoid函数近似计算得这两个item排序的概率。<br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-01.png" style="max-width:300px"></div></li>
<li>根据上述近似概率与真实概率，得到交叉熵损失函数；当个item分数相同时，损失函数为log2，这会使得模型计算得分趋向于分散。<br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-02.png" style="max-width:330px"></div></li>
<li>对真实概率进行了重新定义，得到损失函数新的写法。<br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-03.png" style="max-width:330px"></div></li>
<li>计算损失函数对得分的导数，并得到梯度下降中参数的更新计算。<br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-04.png" style="max-width:400px"></div><br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-05.png" style="max-width:400px"></div></li>
<li>论文强调了学习率是正数，但这个应该是直观的，不然不就往反方向更新了。<br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-06.png" style="max-width:450px"></div></li>
</ul>
</li>
<li>
<p>加速RankNet的训练</p>
<ul>
<li>根据上文，可以得到损失函数对参数的导数。<br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-07.png" style="max-width:480px"></div><br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-08.png" style="max-width:400px"></div></li>
<li>避免两个item重复计算，将n方次计算简化为一半；并将每个item的lambda聚合，其含义近似为文档排在前面的倾向系数。<br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-09.png" style="max-width:400px"></div><br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-10.png" style="max-width:280px"></div></li>
</ul>
</li>
<li>
<p>信息检索的评分标准</p>
<ul>
<li>MRR(Mean Reciprocal Rank)，平均倒数排名，其中Q是查询数量，ranki是相关结果所在位置，只能度量每次只有一个相关结果的情况。<br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-11.png" style="max-width:280px"></div></li>
<li>MAP(Mean Average Precision)，平均正确率均值，计算所有相关结果的准确率之和。<br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-12.png" style="max-width:320px"></div></li>
<li>NDCG(Normalized Discounted Cumulative Gain)，归一化折损累积增益，其中li为相关程度（文中举例取值范围为0～4），maxDCG即是最佳排序的DCG值。<br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-13.png" style="max-width:280px"></div><br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-14.png" style="max-width:280px"></div></li>
<li>ERR(Expected Reciprocal Rank)，预期倒数排名，目的是改善NDCG计算当前位置得分未考虑前面item的情况。<br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-15.png" style="max-width:200px"></div><br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-16.png" style="max-width:170px"></div></li>
</ul>
</li>
<li>
<p>LambdaRank</p>
<ul>
<li>在排序中，我们在大部分情况下应该是更希望下图左边的情况，而下图两种情况只有NDCG和ERR才能区分出来，但这两种评分标准是不可导的，所以就有了LambdaRank。<br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-17.png" style="max-width:300px"></div></li>
<li>在RankNet中，损失函数是通过交叉熵计算所得，为了引入NDCG等指标，可以将两个item交换位置之后的指标差值作为系数引入，其中label为0项被省略了。<br />
<div style="text-align: center"><img src="/wiki/attach/images/pairwise-18.png" style="max-width:300px"></div></li>
<li>由于梯度代表着参数更新的方向与强度，将梯度乘以类似于NDCG的指标差，会使得更新过程中更重视指标差值更大的pair，拉开不同相关性item的预测值的差距。</li>
</ul>
</li>
<li>
<p>LambdaMART</p>
<ul>
<li>MART和GBDT基本是一个思路，多个弱学习器的组合，每次新增弱学习器学习的都是当前预测值和真实值的残差，常用的弱学习器是树模型。</li>
<li>由于LambdaRank定义了梯度，所以LambdaMART就可以利用GBDT来学习，具体过程就不再赘述。</li>
</ul>
</li>
</ul>
    </div>
    <div id="footer">
      <span>
        <p>Copyright © 2021 zwt.
        Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.</p>
        <p>Site Generated 2021-06-19 16:21:34</p>
      </span>
    </div>

    
    
  </body>
</html>