<!DOCTYPE HTML>
<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="Atom feed">
    <title>2023-PIER: Permutation-Level Interest-Based End-to-End Re-ranking Framework in E-commerce - zwt的个人wiki</title>
    <meta name="keywords" content="Memory."/>
    <meta name="description" content="Wiki."/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  </head>

  <body>
  <div id="container" style = "width: 65em">
      
<div id="header">
  <div class="post-nav"><a href="/wiki/">Home</a>&nbsp;&#187;&nbsp;<a href="/wiki/#02-Recommend System">02-Recommend System</a>&nbsp;&#187;&nbsp;2023-PIER: Permutation-Level Interest-Based End-to-End Re-ranking Framework in E-commerce
    <span class="updated">Page Updated&nbsp;
      2024-01-08
    </span></div>
</div>
<div class="clearfix"></div>

<div class="page_title">2023-PIER: Permutation-Level Interest-Based End-to-End Re-ranking Framework in E-commerce</div>

  <h2 id="_1">总结</h2>
<ul>
<li>提出了两阶段的端到端的重排解决方案。</li>
</ul>
<h2 id="_2">主要内容</h2>
<ul>
<li>
<p>整体流程：暴力生成序列、FPSM选择tok-k的序列、OCPM选择最优序列<br />
<div style="text-align: center"><img src="/wiki/attach/images/PIER-01.png" style="max-width:600px"></div></p>
</li>
<li>
<p>模型结构<br />
<div style="text-align: center"><img src="/wiki/attach/images/PIER-02.png" style="max-width:800px"></div></p>
</li>
<li>
<p>序列推荐中的sideinfo</p>
<ul>
<li>side info+id直接融合+self-attention（信息侵入，id信息不再准确）</li>
<li>id和side info分开self-attention建模最后合并（id和side info缺乏交互）</li>
<li>id仅作为self-attention的value，特征和id作为q、k（解决信息侵入问题，但所有side info重要性一致）</li>
<li>每个side info单独的k和q再融合（特征之间没有交互）</li>
<li>二维的transfomer，每个特征+item_id都会和其他所有特征+item_id 计算attention（复杂度高）</li>
</ul>
</li>
<li>
<p>simhash</p>
<ul>
<li>ann相似度搜索方法（树、lsh、矢量量化）</li>
<li>simhash是lsh的一种，步骤为（分词、hash、加权、合并、降维），包含类似item的情况下最后hash的结果相似</li>
</ul>
</li>
<li>
<p>对比学习（无监督或者自监督学习方法）</p>
<ul>
<li>positive pair特征相似度高loss小，negative pair特征相似度低loss大</li>
<li>Triplet loss，query和正负样本</li>
<li>(N+1)-tuplet loss，扩充为N个负样本</li>
<li>N-pair loss，把其他正样本当成该正样本的负样本，batch内负采样，减少计算量</li>
</ul>
</li>
</ul>
<div style="text-align: center"><img src="/wiki/attach/images/PIER-03.png" style="max-width:800px"></div>

<div style="text-align: center"><img src="/wiki/attach/images/PIER-04.png" style="max-width:800px"></div>
    </div>
    <div id="footer">
      <span>
        <p>Copyright © 2024 zwt.
        Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.</p>
        <p>Site Generated 2024-11-26 17:23:21</p>
      </span>
    </div>

    
    
  </body>
</html>