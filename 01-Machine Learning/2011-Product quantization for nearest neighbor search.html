<!DOCTYPE HTML>
<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="Atom feed">
    <title>2011-Product quantization for nearest neighbor search - zwt的个人wiki</title>
    <meta name="keywords" content="Memory."/>
    <meta name="description" content="Wiki."/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  </head>

  <body>
  <div id="container" style = "width: 65em">
      
<div id="header">
  <div class="post-nav"><a href="/wiki/">Home</a>&nbsp;&#187;&nbsp;<a href="/wiki/#01-Machine Learning">01-Machine Learning</a>&nbsp;&#187;&nbsp;2011-Product quantization for nearest neighbor search
    <span class="updated">Page Updated&nbsp;
      2020-05-13
    </span></div>
</div>
<div class="clearfix"></div>

<div class="page_title">2011-Product quantization for nearest neighbor search</div>

  <h2 id="_1">主要内容</h2>
<ul>
<li>
<p>Backgroud</p>
<ul>
<li>量化是指将数据通过某种函数映射到有限集合的过程，分为标量量化和矢量量化。</li>
<li>标量量化是指维度为1的矢量量化，一个p维最佳矢量量化器性能总是优于p个最佳标量量化器，但矢量量化的复杂度更高。</li>
<li>衡量的标准为，相同的编码速率下，矢量量化的失真度更小。</li>
</ul>
</li>
<li>
<p>加速相似度搜索的方法</p>
<ul>
<li>基于树的方法，如KD树</li>
<li>Hash方法，如LSH</li>
<li>矢量量化方法，如乘积量化PQ</li>
</ul>
</li>
<li>
<p>矢量量化（Vector Quantization）</p>
<ul>
<li>普通的量化是单维的，矢量量化是指将数据在多维空间中进行整体量化。相比于单维量化，矢量量化考虑了数据各个维度之间的关系，量化效果更好。</li>
<li>优化目标是失真度，如原始数据与量化后数据向量差的F范数。</li>
</ul>
</li>
<li>
<p>倒排 —— 减少相似度计算次数</p>
<ul>
<li>利用K-means对数据做聚类，得到数据对应的聚类中心，即索引。</li>
<li>将待搜索数据与聚类中心先比较，选取前n个聚类中心，再将待待搜索数据与这n个聚类中心对应的数据计算相似度即可。</li>
</ul>
</li>
<li>
<p>VLAD（vector of locally aggregated descriptors） —— 数据有多个特征向量</p>
<ul>
<li>获得数据的d维特征向量</li>
<li>将所有数据利用d维特征向量聚类得到k个聚类中心</li>
<li>把每一个数据所有的特征向量映射到k个聚类中心</li>
<li>对每个数据所有的特征向量与对应的聚类中心做残差和</li>
<li>对这个残差和做L2归一化，然后拼接成一个K*d的长向量。</li>
<li>上述e步骤得到的就是数据VLAD特征，将所有数据计算得到VLAD特征后存储到数据库，之后对查询数据做上述操作，与数据库中对比即可。</li>
</ul>
</li>
<li>
<p>乘积量化PQ（Product Quantization）—— 减少内存使用， 提高速度</p>
<ul>
<li>乘积量化中的乘积是指笛卡尔积（Cartesian product），具体是把原始向量空间分解为m个低维向量空间的笛卡尔积，并对分解得到的低维向量空间分别做量化，使得向量由多个低维空间的量化code组合表示。</li>
<li>具体的，它将d维当原始向量划分为m个组，对每一组都用k-means算法聚类得到码本，所以一共得到m个码本。之后将向量分别对应到每个码本中，并利用笛卡尔积得到向量的编码结果。</li>
<li>当m=1时，乘积量化就等价于矢量量化，当m=d时，相当于对向量的每一维都用kmeans计算码本。</li>
</ul>
</li>
<li>
<p>搜索方式</p>
<ul>
<li>建立好乘积量化器后，需要利用相似度搜索方式做搜索，主要包括SDC(symmetric distance computation)，ADC(asymmetric distance computation)</li>
</ul>
</li>
<li>
<p>PQ的改进——基于PQ的倒排索引</p>
<ul>
<li>当数据量n&gt;&gt;kd时，对计算量影响较大的还是数据量n，虽然PQ已经做了一定的简化，但计算量还是很大，所以就提出了基于倒排索引的PQ，其步骤如下：</li>
<li>粗量化，利用k-means将原始数据分为k个类别，k取值在sqrt(n)附近。</li>
<li>计算每个数据和其对应类别中心的残差，分别对每个类别中数据的上述残差做PQ量化。用PQ处理残差，而不是原始数据的原因是残差的方差或者能量比原始数据的方差或者能量要小。</li>
<li>在Faiss中具体实现基于PQ的倒排索引时又做了一些处理，具体步骤如下：</li>
<li>n个样本点利用k-means粗聚类，得到k个聚类中心</li>
<li>对每个聚类中心的数据进行采样，得到ns个采样数据</li>
<li>计算这ns个数据与聚类中心的残差</li>
<li>用PQ处理上述ns个残差，得到码本</li>
<li>将所有数据映射到上述码本</li>
<li>搜索时由于倒排的原因，需要搜索前几个聚类中心</li>
</ul>
</li>
</ul>
    </div>
    <div id="footer">
      <span>
        <p>Copyright © 2023 zwt.
        Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.</p>
        <p>Site Generated 2023-12-15 17:06:14</p>
      </span>
    </div>

    
    
  </body>
</html>