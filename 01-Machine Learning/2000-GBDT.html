<!DOCTYPE HTML>
<html>
  <head>
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
    <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
    <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
    <link rel="alternate" type="application/atom+xml" href="atom.xml" title="Atom feed">
    <title>2000-Greedy function approximation: a gradient boosting machine - zwt的个人wiki</title>
    <meta name="keywords" content="Memory."/>
    <meta name="description" content="Wiki."/>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  </head>

  <body>
  <div id="container" style = "width: 65em">
      
<div id="header">
  <div class="post-nav"><a href="/wiki/">Home</a>&nbsp;&#187;&nbsp;<a href="/wiki/#01-Machine Learning">01-Machine Learning</a>&nbsp;&#187;&nbsp;2000-Greedy function approximation: a gradient boosting machine
    <span class="updated">Page Updated&nbsp;
      2020-06-21
    </span></div>
</div>
<div class="clearfix"></div>

<div class="page_title">2000-Greedy function approximation: a gradient boosting machine</div>

  <h2 id="_1">总结</h2>
<ul>
<li>将数值优化的思想扩展到函数空间，利用CART（弱学习器）来拟合负梯度，并将弱学习器累加到主函数得到新的主函数。</li>
</ul>
<h2 id="_2">主要内容</h2>
<ul>
<li>
<p>梯度下降法常用来在最优化问题中求参数值，这套理论同样可以利用到函数空间。</p>
</li>
<li>
<p>在GBDT中，利用CART去拟合当前的负梯度，并在线性搜索权值后通过加权求和得到新的函数。</p>
</li>
<li>
<p>后面就介绍了GBDT在各种场景下的应用。</p>
</li>
</ul>
    </div>
    <div id="footer">
      <span>
        <p>Copyright © 2022 zwt.
        Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.</p>
        <p>Site Generated 2022-01-04 22:01:17</p>
      </span>
    </div>

    
    
  </body>
</html>